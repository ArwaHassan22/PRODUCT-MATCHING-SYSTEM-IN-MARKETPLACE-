# -*- coding: utf-8 -*-
"""I Supply Hackathon

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eHXJHWty7mAszOalLjHW32VTrDmeIRe2
"""

!pip install rapidfuzz openpyxl

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
from rapidfuzz import fuzz , process
from openpyxl import load_workbook
import time
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from multiprocessing import Pool, cpu_count

seller_sheet=pd.read_excel('/content/Product Matching Dataset.xlsx',sheet_name='Dataset')

master_sheet=pd.read_excel('/content/Product Matching Dataset.xlsx',sheet_name='Master File')

seller_sheet.head()

seller_sheet.tail()

master_sheet.head()

master_sheet.tail()

seller_sheet.info()

master_sheet.info()

seller_sheet.describe()

seller_sheet.shape

master_sheet.shape

seller_sheet.isnull().sum()

seller_sheet.duplicated().sum()

seller_sheet.drop_duplicates(inplace=True)

seller_sheet.duplicated().sum()

seller_sheet.shape

seller_sheet.head()

master_sheet.isnull().sum()

master_sheet.duplicated().sum()

def clean_text(text):
    text = str(text).lower()
    text = text.replace("س ج", "").strip()
    text = re.sub(r'\bك\b', 'كبسول', text)
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\s+', ' ', text)

    dosage_forms = {
        'tab': 'tablet',
        'caps': 'capsule',
        'cap': 'capsule',
        'كبسولة': 'كبسول'
    }

    for abbrev, full in dosage_forms.items():
        text = text.replace(abbrev, full)

    return text.strip()

seller_sheet['marketplace_product_name_ar']= seller_sheet['marketplace_product_name_ar'].apply(clean_text)
seller_sheet['seller_item_name']= seller_sheet['seller_item_name'].apply(clean_text)

seller_sheet.head()

master_sheet['product_name']= master_sheet['product_name'].apply(clean_text)
master_sheet['product_name_ar'] = master_sheet['product_name_ar'].apply(clean_text)

master_sheet.head()

def extract_features(text):
    features = {
        'concentration': None,
        'dosage_form': None
    }
    concentration_match = re.search(r'\d+\s*(mg|مجم|g|جم)', text)
    if concentration_match:
        features['concentration'] = concentration_match.group()

    dosage_forms = ['tab', 'قرص', 'capsule', 'كبسول', 'syrup', 'شراب']
    for form in dosage_forms:
        if form in text:
            features['dosage_form'] = form
            break

    return features

def get_confidence_level(score):
    if score >= 90:
        return "High"
    elif 70 <= score < 90:
        return "Medium"
    else:
        return "Low"

def find_best_match(seller_item_name, master_sheet, lang='ar'):
    start_time = time.time()
    if lang == 'ar':
        query = seller_item_name
        choices = master_sheet['product_name_ar'].tolist()
    else:
        query = seller_item_name
        choices = master_sheet['product_name'].tolist()

    query_features = extract_features(query)

    best_match = None
    best_score = 0

    for choice in choices:

        choice_features = extract_features(choice)


        if query_features['concentration'] == choice_features['concentration'] and \
           query_features['dosage_form'] == choice_features['dosage_form']:
            score = fuzz.token_sort_ratio(query, choice)
            if score > best_score:
                best_score = score
                best_match = choice

    end_time = time.time()
    execution_time = (end_time - start_time) * 1000
    print(f"Time taken for matching: {execution_time:.2f} ms")

    if execution_time > 500:
        print(f"Warning: Matching took {execution_time:.2f} ms, which exceeds the 500 ms limit.")


    similarity_score = best_score / 100

    if best_score >= 90:
        matched_row = master_sheet[master_sheet[f'product_name{"" if lang == "en" else "_ar"}'] == best_match].iloc[0]
        confidence_level = get_confidence_level(best_score)
        return matched_row['sku'], similarity_score, best_match, confidence_level
    else:
        confidence_level = get_confidence_level(best_score)
        return None, similarity_score, best_match, confidence_level
def process_chunk(chunk, master_sheet, lang):
    results = chunk.apply(lambda x: find_best_match(x, master_sheet, lang))
    return results

def parallel_processing(seller_sheet, master_sheet, lang, chunk_size=1000):
    chunks = [seller_sheet[i:i + chunk_size] for i in range(0, seller_sheet.shape[0], chunk_size)]
    with Pool(cpu_count()) as pool:
        results = pool.starmap(process_chunk, [(chunk, master_sheet, lang) for chunk in chunks])
    return pd.concat(results)

seller_sheet['sku_en'], seller_sheet['score_en'], seller_sheet['matched_name_en'], seller_sheet['confidence_en'] = zip(*seller_sheet['seller_item_name'].apply(
    lambda x: find_best_match(x, master_sheet, 'en')
))


seller_sheet['sku_ar'], seller_sheet['score_ar'], seller_sheet['matched_name_ar'], seller_sheet['confidence_ar'] = zip(*seller_sheet['marketplace_product_name_ar'].apply(
    lambda x: find_best_match(x, master_sheet, 'ar')
))

def select_best_match(row):
    if row['score_en'] >= row['score_ar']:
        return row['sku_en'] if row['sku_en'] is not None else row['matched_name_en'], row['score_en'], row['confidence_en']
    elif row['score_ar'] >= row['score_en']:
        return row['sku_ar'] if row['sku_ar'] is not None else row['matched_name_ar'], row['score_ar'], row['confidence_ar']
    else:
        return None, 0, "Low Confidence"

seller_sheet['Expected SKU'], seller_sheet['Similarity Score'], seller_sheet['Confidence Level'] = zip(*seller_sheet.apply(select_best_match, axis=1))

seller_sheet.drop(columns=['sku_en', 'score_en', 'matched_name_en', 'confidence_en', 'sku_ar', 'score_ar', 'matched_name_ar', 'confidence_ar'], inplace=True)

seller_sheet.head()

seller_sheet

if 'sku' in seller_sheet.columns:

    correct_predictions = (seller_sheet['Expected SKU'] == seller_sheet['sku']).sum()

    total_predictions = seller_sheet.shape[0]

    accuracy = (correct_predictions / total_predictions) * 100
    print(f'Accuracy: {accuracy:.2f}%')
else:
    print("Accuracy less than expectation")

seller_sheet.to_excel('matched_products.xlsx', index=False)